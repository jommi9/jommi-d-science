---
title: "Predicting Daily Deal sales numbers"
output: html_notebook
---

*This is an experimental R Notebook serving as my introduction to the world of code notebooks, and also as a submission for my assignemnt to the course "Marketing Analytics" by Professor Sky Liang.*

###Importing, describing, and refining the data
First we import the "dailydeal.csv" data set.
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(readr)
dailydeal <- read_csv("dailydeal.csv")
install.packages("ggplot2")
install.packages("rmisc")
library(ggplot2)
```
 
The data contains the following variables as explained by the exercise outline :

| name | description |
|:---|:---------|:--------|
| ID | a unique ID for each daily deal |
| date_added | the date on which the daily deal was added |
| date_ended | the date on which the daily deal was ended |
| site | the website on which the daily deal was posted |
| value | the value of the deal *(in dollars)* |
| discount | discount percentage *(if Value 100, discount 40 = price paid 60)*  | 
| **sold** | sales number, i.e., the number of customers who purchased the deal |
| MerchantID | a unique ID for each merchant |
| category | deal category |

First of all, we can take the **sold** variable out of consideration. This is because it is our dependant variable -- our "y" value:  
*It's the thing we want to predict.*

**So, which of these leftover variables do we think to be useful in predicting daily deal sales?**

After doing a quick google search, I found a great [article](http://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch10.pdf) article about choosing variables. It outlines tips for variable selection and different methods to accomplish it:  

>1.  Explain the data in the simplest way â€” **redundant** predictors should be removed.
2. **Unnecessary** predictors will add noise to the estimation of other quantities that we are interested in. 
3. **Collinearity** is caused by having too many variables trying to do the same job.  
4. **Cost:** if the model is to be used for prediction, we can save time and/or money by not measuring  
redundant predictors.


It advises that prior to variable selection one should:  

>1.  Identify outliers and influential points - maybe exclude them at least temporarily.  

Quickly checking the data it seems like there are some weird occurances. The **"value"** variable has a huge range going from **8** to **30 000**, and the **"sales"** variable ranges from **0** to **20542**. The **"discount"** variable has **4** values with the amount **"0.0"**, which would mean no discount.

```{r message=FALSE, warning=FALSE}
#Delete the 0 discount entries
dailydeal$discount[which(dailydeal$discount==0)] = NA_character_
invisible(complete.cases(dailydeal))
dailydeal$discount <- as.numeric(dailydeal$discount)
```

```{r}
#Examine ranges
par(mfrow=c(1, 3))
boxplot(dailydeal$discount, main="discount")
boxplot(dailydeal$value, main="value")
boxplot(dailydeal$sold, main="sold")
```

To combat this we could remove the outliers in percentage way, such as removing the top and bottom 1%. For now we will keep them in the data, but we will be ready to remove them if they present a problem.

>2.  Add in any transformations of the variables that seem appropriate. 

We *could* do some basic date categorization, like encoding holidays etc. However for now that is out of scope for this project.  
One thing we willd do with dates is to remove the effect of the promotion length on the amount of sales.   Otherwise promotions that run for longer times have a natural inclination to have moresales.  
We will create new variable called **"days"**, and through this another variabled called **"sold_daily"**.

```{r}
days <- cbind(difftime(dailydeal$date_ended, dailydeal$date_added, units = "days")+1)
days[days == 0] <- 1
dailydeal$days <- days
sold_daily <- cbind(dailydeal$sold / dailydeal$days)
dailydeal$sold_daily <- sold_daily

```
Now we have a new column that outlines the amount sold per day. Thus we will get us more accurate results.  

Another problem is that the **"discount"** variable is measured in percantage points. But that's not the only way people look at discounts in real life. A 10% discount on a car is much more valuable than a 50% discount on a choclate bar. So we need to create a new variable **"discount_amount"**, which is calculated through `value X discount X 0.01`. In addition to this, we create new variables for sold_dollar(in dollars), and sold_dollar_discounted(in dollars and discount is applied)

```{r}
discount_amount <- cbind(dailydeal$value*dailydeal$discount*0.01)
dailydeal$discount_amount <- discount_amount
sales_dollar <- cbind(dailydeal$sold_daily * dailydeal$value)
dailydeal$sales_dollar <- sales_dollar
sales_dollar_discounted <- cbind(dailydeal$sold_daily * (dailydeal$value-dailydeal$discount_amount))
dailydeal$sales_dollar_discounted <- sales_dollar_discounted
```


###Building regression models

So now that we have evaluated the variables we have available to us, we can start building regression models based on our analysis.

First starting with some plots of univariate analysis:

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(Rmisc)
p1 <- qplot( dailydeal$discount, dailydeal$sales_dollar, log="y") + geom_smooth(method = lm) + ggtitle("A1")
p2 <- qplot( dailydeal$discount, dailydeal$sales_dollar_discounted, log="y") + geom_smooth(method = lm)+ ggtitle("B1")
p3 <- qplot( dailydeal$discount_amount, dailydeal$sales_dollar, log="y") + geom_smooth(method = lm)+ ggtitle("A2")
p4 <- qplot( dailydeal$discount_amount, dailydeal$sales_dollar_discounted, log="y") + geom_smooth(method = lm)+ ggtitle("B2")
p5 <- qplot( dailydeal$discount, dailydeal$sold_daily, log="y") + geom_smooth(method = lm)+ ggtitle("A3")
p6 <- qplot( dailydeal$discount_amount, dailydeal$sold_daily, log="y") + geom_smooth(method = lm)+ ggtitle("B3")
multiplot(p1,p2,p3,p4,p5,p6, cols=3)
```

These six graphs give us quite a bit of insights. The first column is especially interesting. In graph A1, you can see a preliminary positive correlation between how big of a discount percentage you advertise, and your total sales amount. You see the same in A2, where we inspect the actual amount discounted. This is basic economics 101: When a product's price lowers, the sales amount increases.

However, what the graphs also show is that the effect might not be a net-positive at all. If you look at graphs A3, B1 and B3 you see a negative slope forming. A3 suggests products that had a higher discount amount **sold less daily**! This is goes heavily against intuition!

###Testing predictions to real data

We're going to use the average deviance to analyze the model:
$$ AverageDeviance=\sqrt{\frac{\sum^{N}_{i=1}({y_i-\hat{y}_i})^2}{N}}$$
Where N is the number of observations in year 2013, yi is the observed sales for the i:th deal and y hat is the model predicted sales for the i:th deal.


###Conclusions and improvements

It would be interesting to get the cost incorporated in the model as well, but it might actually not even help that much, as the discount itself is already a certain type of "cost".

Usually an important aspect of these "daily deals" is getting new people to try your service/product. If we had data on which portion of the sales were new customers, we could evaluate further the effect of the discount deal.  


